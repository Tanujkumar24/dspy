{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1baed26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dspy in f:\\anaconda\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: backoff>=2.2 in f:\\anaconda\\lib\\site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in f:\\anaconda\\lib\\site-packages (from dspy) (1.5.2)\n",
      "Requirement already satisfied: openai>=0.28.1 in f:\\anaconda\\lib\\site-packages (from dspy) (1.107.2)\n",
      "Requirement already satisfied: regex>=2023.10.3 in f:\\anaconda\\lib\\site-packages (from dspy) (2025.9.1)\n",
      "Requirement already satisfied: orjson>=3.9.0 in f:\\anaconda\\lib\\site-packages (from dspy) (3.11.1)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in f:\\anaconda\\lib\\site-packages (from dspy) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in f:\\anaconda\\lib\\site-packages (from dspy) (2.31.0)\n",
      "Requirement already satisfied: optuna>=3.4.0 in f:\\anaconda\\lib\\site-packages (from dspy) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in f:\\anaconda\\lib\\site-packages (from dspy) (2.11.4)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in f:\\anaconda\\lib\\site-packages (from dspy) (0.1.6)\n",
      "Requirement already satisfied: litellm>=1.64.0 in f:\\anaconda\\lib\\site-packages (from dspy) (1.77.1)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in f:\\anaconda\\lib\\site-packages (from dspy) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in f:\\anaconda\\lib\\site-packages (from dspy) (0.50.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in f:\\anaconda\\lib\\site-packages (from dspy) (9.1.2)\n",
      "Requirement already satisfied: anyio in f:\\anaconda\\lib\\site-packages (from dspy) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in f:\\anaconda\\lib\\site-packages (from dspy) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in f:\\anaconda\\lib\\site-packages (from dspy) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in f:\\anaconda\\lib\\site-packages (from dspy) (3.1.1)\n",
      "Requirement already satisfied: rich>=13.7.1 in f:\\anaconda\\lib\\site-packages (from dspy) (14.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in f:\\anaconda\\lib\\site-packages (from dspy) (2.1.2)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in f:\\anaconda\\lib\\site-packages (from dspy) (3.5.0)\n",
      "Requirement already satisfied: gepa==0.0.7 in f:\\anaconda\\lib\\site-packages (from gepa[dspy]==0.0.7->dspy) (0.0.7)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\anaconda\\lib\\site-packages (from anyio->dspy) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\anaconda\\lib\\site-packages (from anyio->dspy) (1.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in f:\\anaconda\\lib\\site-packages (from anyio->dspy) (4.13.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (3.11.18)\n",
      "Requirement already satisfied: click in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (8.2.0)\n",
      "Requirement already satisfied: fastuuid>=0.12.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (0.12.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (4.25.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in f:\\anaconda\\lib\\site-packages (from litellm>=1.64.0->dspy) (0.13.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\anaconda\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy) (2.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in f:\\anaconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in f:\\anaconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in f:\\anaconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in f:\\anaconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\anaconda\\lib\\site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in f:\\anaconda\\lib\\site-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\anaconda\\lib\\site-packages (from pydantic>=2.0->dspy) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\anaconda\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.20.0)\n",
      "Requirement already satisfied: certifi in f:\\anaconda\\lib\\site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\anaconda\\lib\\site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in f:\\anaconda\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy) (3.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\anaconda\\lib\\site-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\anaconda\\lib\\site-packages (from openai>=0.28.1->dspy) (0.9.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in f:\\anaconda\\lib\\site-packages (from optuna>=3.4.0->dspy) (1.16.5)\n",
      "Requirement already satisfied: colorlog in f:\\anaconda\\lib\\site-packages (from optuna>=3.4.0->dspy) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\anaconda\\lib\\site-packages (from optuna>=3.4.0->dspy) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in f:\\anaconda\\lib\\site-packages (from optuna>=3.4.0->dspy) (2.0.41)\n",
      "Requirement already satisfied: PyYAML in f:\\anaconda\\lib\\site-packages (from optuna>=3.4.0->dspy) (6.0.2)\n",
      "Requirement already satisfied: Mako in f:\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\lib\\site-packages (from requests>=2.31.0->dspy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\lib\\site-packages (from requests>=2.31.0->dspy) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\anaconda\\lib\\site-packages (from rich>=13.7.1->dspy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\anaconda\\lib\\site-packages (from rich>=13.7.1->dspy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.0)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\anaconda\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy) (2.0.1)\n",
      "Requirement already satisfied: colorama in f:\\anaconda\\lib\\site-packages (from tqdm>=4.66.1->dspy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U dspy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff38bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d49abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy version: 3.0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"DSPy version:\", dspy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0431245",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=dspy.LM(\"gemini/gemini-2.5-flash\", api_key=\"AIzaSyBGpmviDEBJiPpi44vyZOHvO7Zen-1Cmus\")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83908564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='To find the probability, we need to determine the number of favorable outcomes and divide it by the total number of possible outcomes.\\n\\n1.  **Total Possible Outcomes:**\\n    When two dice are tossed, each die has 6 faces (1, 2, 3, 4, 5, 6).\\n    The total number of possible outcomes is 6 * 6 = 36.\\n    These outcomes can be represented as pairs (die1, die2):\\n    (1,1), (1,2), (1,3), (1,4), (1,5), (1,6)\\n    (2,1), (2,2), (2,3), (2,4), (2,5), (2,6)\\n    (3,1), (3,2), (3,3), (3,4), (3,5), (3,6)\\n    (4,1), (4,2), (4,3), (4,4), (4,5), (4,6)\\n    (5,1), (5,2), (5,3), (5,4), (5,5), (5,6)\\n    (6,1), (6,2), (6,3), (6,4), (6,5), (6,6)\\n\\n2.  **Favorable Outcomes (Sum equals two):**\\n    We need to find the combinations where the sum of the two dice is 2.\\n    The only combination that results in a sum of 2 is (1, 1).\\n    So, there is only 1 favorable outcome.\\n\\n3.  **Calculate Probability:**\\n    Probability = (Number of Favorable Outcomes) / (Total Possible Outcomes)\\n    Probability = 1 / 36\\n\\n4.  **Convert to float:**\\n    1 / 36 = 0.027777777777777776',\n",
       "    answer=0.027777777777777776\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "math(question=\"Two dice are tossed. What is the probability that the sum equals two?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473302c8",
   "metadata": {},
   "source": [
    "# basic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea8af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Paris\n"
     ]
    }
   ],
   "source": [
    "predict=dspy.Predict(\"question -> answer\")\n",
    "response= predict(question= \"what is the capital city of france\")\n",
    "print(f\"answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5fc41",
   "metadata": {},
   "source": [
    "# signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171a98e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: RCB won the IPL 2025.\n"
     ]
    }
   ],
   "source": [
    "class QnaSignature(dspy.Signature):\n",
    "    \"\"\"\" Answer the question based on the context provided\"\"\"\n",
    "    question= dspy.InputField(desc=\"the question to be answered.\")\n",
    "    context= dspy.InputField(desc=\"the context to answer the question.\")\n",
    "    answer=dspy.OutputField(desc=\"the answer to the question\")\n",
    "    \n",
    "#create a module that uses the Signature\n",
    "Predicator= dspy.Predict(QnaSignature)\n",
    "result= Predicator(question= \"which team won ipl 2025 ?\",\n",
    "                  context= \"in june 2025, ipl final was held at naredra modi stadium , punjab and rcb played final match and finally rcb won the ipl after 18 years and its 18th year  \")\n",
    "\n",
    "print(\"response:\",result.answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c602ca",
   "metadata": {},
   "source": [
    "# Chain Of Thaught"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8ef4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: \n",
      " The problem asks for the total number of apples in three boxes. To find the total, I need to add the number of apples in each box together. The number of apples in the boxes are 4, 5, and 6.\n",
      "final answer: 15\n"
     ]
    }
   ],
   "source": [
    "class MathSig(dspy.Signature):\n",
    "    \"\"\"\"solve the problem , include step by step reasoning then final answer \"\"\"\n",
    "    problem= dspy.InputField(desc=\"math problem as text\")\n",
    "    resoning=dspy.OutputField(desc=\"step by step chain of thaught\")\n",
    "    finalAnswer=dspy.OutputField(desc=\"conceise the final answer\")\n",
    "    \n",
    "solver=dspy.ChainOfThought(MathSig)\n",
    "\n",
    "res=solver(problem=\"if 3 boxes contain 4,5,6 apples, how many applles are there in total? \" )\n",
    "print(\"Reasoning: \\n\", getattr(res, \"reasoning\",res.get(\"reasoning\")))\n",
    "\n",
    "print(\"final answer:\", getattr(res, \"final answer\", res.get(\"finalAnswer\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d57bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: \n",
      " The problem asks for the total cost of 12 pens, with each pen costing 5 rupees. To find the total cost, I need to multiply the number of pens by the cost of one pen.\n",
      "final answer: The total cost is 60 rupees.\n"
     ]
    }
   ],
   "source": [
    "class MathReasoning(dspy.Signature):\n",
    "    \"\"\"\"solve the problem , include step by step reasoning then final answer \"\"\"\n",
    "    problem= dspy.InputField(desc=\"math word problem \")\n",
    "    resoning=dspy.OutputField(desc=\"step by step Reasoning\")\n",
    "    finalAnswer=dspy.OutputField(desc=\"only numeric number \")\n",
    "    \n",
    "solver=dspy.ChainOfThought(MathSig)\n",
    "\n",
    "res=solver(problem=\"a shopkeeper buys 12 pens each costing 5 rupees , how much the total cost ? \" )\n",
    "print(\"Reasoning: \\n\", res.reasoning)\n",
    "\n",
    "print(\"final answer:\", res.finalAnswer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2c0ab",
   "metadata": {},
   "source": [
    "# multi hop question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4933b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning:\n",
      " The question asks for Narendra Modi's birthplace and birthday. The context states that he was \"born 17 September 1950\" and \"Modi was born and raised in Vadnagar, Bombay State (present-day Gujarat)\". I will extract these two pieces of information.\n",
      "finalanswer: Narendra Modi was born in Vadnagar, Bombay State (present-day Gujarat), and his birthday is on 17 September 1950.\n"
     ]
    }
   ],
   "source": [
    "class MultiHopQA(dspy.Signature):\n",
    "    question=dspy.InputField()\n",
    "    context=dspy.InputField()\n",
    "    reasoning=dspy.OutputField()\n",
    "    finalAnswer=dspy.OutputField()\n",
    "    \n",
    "qa= dspy.ChainOfThought(MultiHopQA)\n",
    "context= \"\"\"\" Narendra Damodardas Modi[a] (born 17 September 1950) is an Indian politician who has served as the prime minister of India since 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the member of parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right-wing Hindutva paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\n",
    "\n",
    "Modi was born and raised in Vadnagar, Bombay State (present-day Gujarat), where he completed his secondary education. He was introduced to the RSS at the age of eight, becoming a full-time worker for the organisation in Gujarat in 1971. The RSS assigned him to the BJP in 1985, and he rose through the party hierarchy, becoming general secretary in 1998.[b] In 2001\"\"\"\n",
    "\n",
    "res=qa(question=\"where did naredra modi born and when is his birthday?\",context=context)\n",
    "\n",
    "print(\"reasoning:\\n\", res.reasoning)\n",
    "print(\"finalanswer:\", res.finalAnswer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce525bf5",
   "metadata": {},
   "source": [
    "# RAG+Chain of thaught"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08f27d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning:\n",
      "  The context explicitly states the strategic objective of Operation Sindoor. It mentions that the politico-military objective was \"to punish Pakistan for provocations and to punish terrorism at its roots.\" This directly answers the question about the cause of the operation.\n",
      "finalanswer: Operation Sindoor was launched to punish Pakistan for provocations and to punish terrorism at its roots.\n"
     ]
    }
   ],
   "source": [
    "class RagQA(dspy.Signature):\n",
    "    question=dspy.InputField()\n",
    "    context=dspy.InputField()\n",
    "    reasoning=dspy.OutputField()\n",
    "    finalAnswer=dspy.OutputField()\n",
    "    \n",
    "rag_qa = dspy.ChainOfThought(RagQA)\n",
    "docs=\"\"\"peration Sindoor refers to a recent operation where the Indian armed forces targeted terrorist infrastructure in Pakistan and Pakistan-occupied Jammu and Kashmir, leading to Pakistan's request for a cessation of firing on May 10, 2025. Documentaries and official reports detail the tactical success, the role of indigenous defense technology, and India's strategic response, including countering misinformation and highlighting the commitment to dismantle terrorism. \n",
    "Key Aspects of Operation Sindoor\n",
    "Target:\n",
    "The operation targeted terrorist infrastructure in Pakistan and Pakistan-occupied Jammu and Kashmir. \n",
    "Timeline:\n",
    "India launched Operation Sindoor in the early hours of May 7, 2025. \n",
    "Pakistan's Request:\n",
    "Pakistan's Director General of Military Operations requested a cessation of firing on May 10, 2025, which was agreed to the same day. \n",
    "Strategic Objective:\n",
    "The politico-military objective was to punish Pakistan for provocations and to punish terrorism at its roots, according to the Ministry of External Affairs and the Prime Minister. \n",
    "Documents and Media Coverage\n",
    "Documentary: INSIDE OPERATION SINDOOR–The 88 Hours That Defined India by CNN-News18 features former military officials and analysts discussing the operation. \n",
    "Official Press Releases: The Press Information Bureau (PIB) and Ministry of External Affairs (MEA) have published reports on the operation and its implications. \n",
    "News Reports: News18 and YouTube offer detailed coverage of the event and its context. \n",
    "Significance\n",
    "Indigenous Technology:\n",
    "Operation Sindoor highlighted the effectiveness of India's indigenous defense technologies, from air defense systems to drones and net-centric warfare platforms. \n",
    "Information Warfare:\n",
    "India countered a Pakistani misinformation campaign by providing facts, transparency, and digital vigilance. \n",
    "Assertive Stance:\n",
    "The operation solidified India's image as an assertive and resolute nation committed to combating terrorism and defending its territory.\"\"\"\n",
    "\n",
    "res=rag_qa(question =\"what is the cause of operation sindoor\",context=docs)\n",
    "\n",
    "print(\"reasoning:\\n \", res.reasoning)\n",
    "\n",
    "print(\"finalanswer:\", res.finalAnswer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baca233",
   "metadata": {},
   "source": [
    "# REACT = REASON+ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6dd96cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning is a subfield of Artificial Intelligence (AI) that focuses on enabling systems to learn from data, identify patterns, and make decisions or predictions with minimal human intervention. Instead of being explicitly programmed for every task, machine learning algorithms build a model from sample data (known as \"training data\") to automate analytical model building. This allows computers to find hidden insights without being explicitly programmed where to look.\n"
     ]
    }
   ],
   "source": [
    "#dummy retriver\n",
    "class Retriever:\n",
    "    def search(self,query,k=2):\n",
    "        return [f\"doc about {query} with facts.\"]\n",
    "    \n",
    "class QnASig(dspy.Signature):\n",
    "    question=dspy.InputField()\n",
    "    answer=dspy.OutputField()\n",
    "retriever = Retriever()\n",
    "\n",
    "qa_agent=dspy.ReAct(QnASig, tools=[retriever.search])\n",
    "\n",
    "res=qa_agent(question=\"what is Machine Learning?\")\n",
    "print(res.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d2d9e",
   "metadata": {},
   "source": [
    "# E-commerce Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109201f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, we have 5 iPhones in stock.\n"
     ]
    }
   ],
   "source": [
    "class ProductSig(dspy.Signature):\n",
    "    user_request=dspy.InputField()\n",
    "    response=dspy.OutputField()\n",
    "\n",
    "def check_inventory(item: str):\n",
    "    stock = {\"iphone\": 5, \"samsung\": 0}\n",
    "    # normalize item to lowercase so lookups match\n",
    "    item_key = item.lower()\n",
    "    return f\"{item_key} stock : {stock.get(item_key, 'unknown')}\"\n",
    "\n",
    "# Wrap the function as a dspy Tool so the agent can call it\n",
    "check_tool = dspy.Tool(\n",
    "    func=check_inventory,\n",
    "    name=\"check_inventory\",\n",
    "    desc=\"Return the current stock for the given product. Arg name: item (string).\"\n",
    ")\n",
    "\n",
    "# create the agent with the Tool (list of Tool objects)\n",
    "shop_bot = dspy.ReAct(ProductSig, tools=[check_tool])\n",
    "\n",
    "# query the agent\n",
    "res = shop_bot(user_request=\"do you have iphone phones in stock?\")\n",
    "\n",
    "print(res.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b743998",
   "metadata": {},
   "source": [
    "# program of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea9b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deno in f:\\anaconda\\lib\\site-packages (2.4.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install deno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d978b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "class MathsSig(dspy.Signature):\n",
    "    question=dspy.InputField()\n",
    "    answer=dspy.OutputField()\n",
    "    \n",
    "math_solver=dspy.ProgramOfThought(MathsSig)\n",
    "\n",
    "res=math_solver(question=\"what is (25*4)+(60/3)?\")\n",
    "\n",
    "print(res.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068173a",
   "metadata": {},
   "source": [
    "# data cleaning assistant-program of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231099b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "class CleanSig(dspy.Signature):\n",
    "    instruction=dspy.InputField()\n",
    "    cleaned_data=dspy.OutputField()\n",
    "data_cleaner=dspy.ProgramOfThought(CleanSig)\n",
    "res=data_cleaner(instruction=\"remove duplicates from [1,2,2,3,3,4]\")\n",
    "\n",
    "print(res.cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f8e34",
   "metadata": {},
   "source": [
    "# invoice validation-program of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8fba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 12:10:40 ERROR dspy.predict.program_of_thought: Error in code execution: Invalid Python syntax. message: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "class invoiceSig(dspy.Signature):\n",
    "    invoice = dspy.InputField()\n",
    "    total = dspy.OutputField()\n",
    "invoice_solver = dspy.ProgramOfThought(invoiceSig)\n",
    "\n",
    "res=invoice_solver(invoice=\"items are  pen= $10, notebook= $50, bag= $200\")\n",
    "\n",
    "print(res.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8e8e0",
   "metadata": {},
   "source": [
    "# OPTIMIZERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02179cd3",
   "metadata": {},
   "source": [
    "1. BootstrapFewShot\n",
    "\n",
    "Learns a better prompt from a small dataset of examples.\n",
    "\n",
    "Automatically builds few-shot prompts.\n",
    "\n",
    "📌 Example: Customer Support Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9322786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Define signature\n",
    "class SupportSig(dspy.Signature):\n",
    "    query = dspy.InputField()\n",
    "    response = dspy.OutputField()\n",
    "\n",
    "# Base model\n",
    "support_bot = dspy.Predict(SupportSig)\n",
    "\n",
    "# Tiny training set\n",
    "trainset = [\n",
    "    {\"query\": \"How do I reset my password?\", \n",
    "     \"response\": \"Click 'Forgot Password' on login page.\"},\n",
    "    {\"query\": \"Where can I find my invoice?\", \n",
    "     \"response\": \"Invoices are in the Billing section of your account.\"},\n",
    "]\n",
    "\n",
    "# Optimizer\n",
    "opt = dspy.BootstrapFewShot()\n",
    "\n",
    "# Train (this is the key line)\n",
    "optimized_bot = opt.fit(support_bot, trainset=trainset)\n",
    "\n",
    "# Test\n",
    "print(optimized_bot(query=\"How do I change my email address?\").response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012c2b8",
   "metadata": {},
   "source": [
    "# 2. LabeledFewShot\n",
    "\n",
    "Like Bootstrap, but you provide explicitly labeled training data.\n",
    "\n",
    "Ensures controlled optimization.\n",
    "\n",
    "📌 Example: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSig(dspy.Signature):\n",
    "    text = dspy.InputField()\n",
    "    sentiment = dspy.OutputField()\n",
    "\n",
    "sentiment_model = dspy.Predict(SentimentSig)\n",
    "\n",
    "trainset = [\n",
    "    {\"text\": \"I love this product\", \"sentiment\": \"Positive\"},\n",
    "    {\"text\": \"This is terrible\", \"sentiment\": \"Negative\"},\n",
    "]\n",
    "\n",
    "optimizer = dspy.LabeledFewShot()\n",
    "optimized_model = optimizer(sentiment_model, trainset=trainset)\n",
    "\n",
    "print(optimized_model(text=\"Not bad at all\").sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a4c64",
   "metadata": {},
   "source": [
    "# GEPA (Gradient-based Example and Prompt Augmentation)\n",
    "\n",
    "Advanced optimizer:\n",
    "\n",
    "Adds examples automatically.\n",
    "\n",
    "Optimizes instructions based on metrics (accuracy, F1, BLEU, etc).\n",
    "\n",
    "Iterative improvement loop, similar to gradient descent but for prompts.\n",
    "\n",
    "📌 Example: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49894305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractSig(dspy.Signature):\n",
    "    text = dspy.InputField()\n",
    "    company = dspy.OutputField()\n",
    "\n",
    "ner_model = dspy.Predict(ExtractSig)\n",
    "\n",
    "trainset = [\n",
    "    {\"text\": \"Apple launched a new iPhone.\", \"company\": \"Apple\"},\n",
    "    {\"text\": \"Google released AI features.\", \"company\": \"Google\"},\n",
    "]\n",
    "\n",
    "optimizer = dspy.GEPA(metric=\"f1\")\n",
    "optimized_model = optimizer(ner_model, trainset=trainset)\n",
    "\n",
    "print(optimized_model(text=\"Microsoft acquired GitHub\").company)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85ac95",
   "metadata": {},
   "source": [
    "# 🚀 Pipelines in DSPy \n",
    "🔹 What are Pipelines?\n",
    "\n",
    "Think of pipelines as workflows that connect multiple DSPy modules together.\n",
    "\n",
    "Each step in the pipeline transforms inputs → outputs, and the outputs of one module can be passed as inputs to the next.\n",
    "\n",
    "This is where DSPy really shines, because instead of writing long monolithic prompts, you compose small reusable steps.\n",
    "\n",
    "👉 Analogy:\n",
    "Pipelines are like machine learning pipelines (Scikit-learn Pipelines or Airflow DAGs), but for LLM-based reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363049c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing has a wide range of potential applications, including:\n",
      "*   **Drug Discovery and Materials Science:** Simulating molecular structures and chemical reactions to accelerate the development of new drugs, catalysts, and advanced materials.\n",
      "*   **Financial Modeling:** Optimizing financial models for portfolio management, risk analysis, fraud detection, and high-frequency trading.\n",
      "*   **Cryptography and Cybersecurity:** Breaking existing public-key encryption algorithms and enabling the development of new quantum-safe cryptographic methods and quantum key distribution.\n",
      "*   **Optimization Problems:** Solving complex optimization challenges in logistics, supply chain management, traffic flow, scheduling, and manufacturing.\n",
      "*   **Artificial Intelligence and Machine Learning:** Enhancing machine learning algorithms for pattern recognition, data classification, anomaly detection, and natural language processing.\n",
      "*   **Data Science and Big Data Analysis:** Accelerating the processing and analysis of large datasets in fields like genomics, astrophysics, and market research.\n",
      "*   **Weather Forecasting and Climate Modeling:** Developing more accurate climate models and weather predictions.\n",
      "*   **Logistics and Supply Chain:** Optimizing transportation, inventory management, and resource allocation.\n",
      "*   **Quantum Chemistry:** Performing highly accurate calculations for chemical systems to understand bonds and reactions.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Define signatures\n",
    "class RetrieveSignature(dspy.Signature):\n",
    "    query = dspy.InputField(desc=\"User query\")\n",
    "    context = dspy.OutputField(desc=\"Relevant documents\")\n",
    "\n",
    "class AnswerSignature(dspy.Signature):\n",
    "    question = dspy.InputField(desc=\"User question\")\n",
    "    context = dspy.InputField(desc=\"Documents for answering\")\n",
    "    answer = dspy.OutputField(desc=\"Final answer\")\n",
    "\n",
    "# Define modules\n",
    "retriever = dspy.Predict(RetrieveSignature)\n",
    "answerer = dspy.ChainOfThought(AnswerSignature)\n",
    "\n",
    "# Define pipeline\n",
    "def rag_pipeline(question):\n",
    "    docs = retriever(query=question).context\n",
    "    return answerer(question=question, context=docs).answer\n",
    "\n",
    "# Example run\n",
    "print(rag_pipeline(\"What are the applications of quantum computing?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d017801",
   "metadata": {},
   "source": [
    "# Example 2: Industry-level Fraud Detection (Banking)\n",
    "\n",
    "Banks often use LLMs for fraud report triaging:\n",
    "\n",
    "Step 1: Extract key info from the complaint.\n",
    "\n",
    "Step 2: Classify severity (high, medium, low).\n",
    "\n",
    "Step 3: Generate a report summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c60e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediately contact your bank to report the suspicious $500 transactions, providing exact dates and times, for investigation, potential charge reversal, and advice on card security.\n"
     ]
    }
   ],
   "source": [
    "class ExtractSignature(dspy.Signature):\n",
    "    complaint = dspy.InputField()\n",
    "    info = dspy.OutputField()\n",
    "\n",
    "class ClassifySignature(dspy.Signature):\n",
    "    info = dspy.InputField()\n",
    "    severity = dspy.OutputField()\n",
    "\n",
    "class SummarizeSignature(dspy.Signature):\n",
    "    info = dspy.InputField()\n",
    "    severity = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "\n",
    "extractor = dspy.ChainOfThought(ExtractSignature)\n",
    "classifier = dspy.Predict(ClassifySignature)\n",
    "summarizer = dspy.Predict(SummarizeSignature)\n",
    "\n",
    "def fraud_pipeline(complaint):\n",
    "    info = extractor(complaint=complaint).info\n",
    "    severity = classifier(info=info).severity\n",
    "    summary = summarizer(info=info, severity=severity).summary\n",
    "    return summary\n",
    "\n",
    "# Example\n",
    "complaint_text = \"I noticed two suspicious transactions of $500 each on my account.\"\n",
    "print(fraud_pipeline(complaint_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72c2a0",
   "metadata": {},
   "source": [
    "# Multiple chain of thaught\n",
    "What is Multi-Chain-of-Thought (one-line)\n",
    "\n",
    "Run many different chain-of-thought reasoning runs for the same question (different samples / prompts / strategies), then compare/aggregate their final answers to get a more reliable result — i.e., “have many students solve the same problem and take the majority/consensus.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30a5d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '9', 'raw_votes': {'9': 7}}\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from collections import Counter\n",
    "\n",
    "# 1) Signature + CoT\n",
    "class QASig(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    context  = dspy.InputField()\n",
    "    reasoning = dspy.OutputField()\n",
    "    final_answer = dspy.OutputField()\n",
    "\n",
    "cot = dspy.ChainOfThought(QASig)\n",
    "\n",
    "def self_consistent_answer(question, context, tries=7):\n",
    "    answers = []\n",
    "    for _ in range(tries):\n",
    "        # set sampling on the LM (depends on your dspy LM config)\n",
    "        dspy.settings.configure(lm_kwargs={\"temperature\": 0.8})\n",
    "        res = cot(question=question, context=context)\n",
    "        ans = getattr(res, \"final_answer\", None) or res.get(\"final_answer\")\n",
    "        answers.append(ans.strip())\n",
    "    # majority vote\n",
    "    most_common, count = Counter(answers).most_common(1)[0]\n",
    "    return {\"answer\": most_common, \"raw_votes\": dict(Counter(answers))}\n",
    "\n",
    "# Usage\n",
    "out = self_consistent_answer(\"If 3 boxes have 2,3,4 items, how many total?\", \"\")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46149bb",
   "metadata": {},
   "source": [
    "# DSPy MultiChainComparison & Evaluation (Observability)\n",
    "\n",
    "This is where DSPy moves beyond just “making multiple reasoning paths” → it helps you compare, evaluate, and choose the best output in a structured way.\n",
    "\n",
    "🔹 1. What is MultiChainComparison?\n",
    "\n",
    "It’s a DSPy helper/module that allows you to run multiple chains (e.g., several CoTs, or CoT + PoT + ReAct) in parallel, then compare their outputs.\n",
    "\n",
    "Instead of manually writing aggregation code (majority vote, semantic similarity, verifier LLM), you can plug into DSPy’s evaluation and optimization loop.\n",
    "\n",
    "👉 Analogy: If MultiChainOfThought is like running 5 students’ answers, MultiChainComparison is like grading them and picking the best one automatically.\n",
    "\n",
    "🔹 2. Why it matters (real-world pain point)\n",
    "\n",
    "In production, you can’t afford to just trust one chain-of-thought.\n",
    "\n",
    "You also can’t manually inspect every reasoning trace.\n",
    "\n",
    "You need an automatic evaluator that can:\n",
    "\n",
    "Check correctness.\n",
    "\n",
    "Check factual grounding.\n",
    "\n",
    "Check format compliance.\n",
    "\n",
    "Choose the best candidate.\n",
    "\n",
    "This is exactly what MultiChainComparison helps automate.\n",
    "\n",
    "🔹 3. Example: Using MultiChainComparison\n",
    "\n",
    "Imagine you’re building a math tutor bot. You want the model to reason step by step, but sometimes it makes arithmetic slips.\n",
    "\n",
    "import dspy\n",
    "\n",
    "class MathSig(dspy.Signature):\n",
    "    question = dspy.InputField(desc=\"Math problem to solve\")\n",
    "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning\")\n",
    "    answer = dspy.OutputField(desc=\"Final numeric answer\")\n",
    "\n",
    "# Define reasoning modules\n",
    "cot = dspy.ChainOfThought(MathSig)\n",
    "pot = dspy.ProgramOfThought(MathSig)\n",
    "\n",
    "# MultiChainComparison\n",
    "multi = dspy.MultiChainComparison(\n",
    "    modules=[cot, pot], \n",
    "    scoring=\"exact_match\"   # or \"semantic_f1\", or a custom evaluator\n",
    ")\n",
    "\n",
    "res = multi(question=\"If a train moves at 60 km/h for 2 hours, how far?\")\n",
    "print(res.answer)\n",
    "\n",
    "\n",
    "✅ DSPy will:\n",
    "\n",
    "Run both CoT and PoT.\n",
    "\n",
    "Score their answers.\n",
    "\n",
    "Pick the best.\n",
    "\n",
    "Return the result.\n",
    "\n",
    "🔹 4. Industry-level Example: Customer Support Bot\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "Retriever: Pulls knowledge base articles.\n",
    "\n",
    "Answer Modules:\n",
    "\n",
    "CoT (natural reasoning).\n",
    "\n",
    "ReAct (tool-augmented with DB lookups).\n",
    "\n",
    "PoT (structured JSON output).\n",
    "\n",
    "MultiChainComparison: Evaluate all answers with a custom scoring function (e.g., Semantic F1 vs. ground truth answers, or LLM verifier checking for hallucinations).\n",
    "\n",
    "def custom_score(candidate, reference):\n",
    "    # Use semantic similarity, regex checks, or LLM verification\n",
    "    if \"account\" in candidate.lower():\n",
    "        return 1.0\n",
    "    return 0.5\n",
    "\n",
    "multi = dspy.MultiChainComparison(\n",
    "    modules=[cot, react, pot],\n",
    "    scoring=custom_score\n",
    ")\n",
    "\n",
    "out = multi(question=\"How do I reset my account password?\",\n",
    "            context=\"Password reset steps: ...\")\n",
    "print(out.answer)\n",
    "\n",
    "\n",
    "✅ Benefit:\n",
    "\n",
    "Ensures the most relevant, grounded answer gets chosen.\n",
    "\n",
    "Reduces hallucination in sensitive industries like finance, healthcare, or enterprise SaaS.\n",
    "\n",
    "🔹 5. Production Best Practices\n",
    "\n",
    "Evaluator choices:\n",
    "\n",
    "Use semantic-F1 for free-text answers.\n",
    "\n",
    "Use exact-match for short/numeric answers.\n",
    "\n",
    "Use a Verifier LLM for complex compliance checks.\n",
    "\n",
    "Logging: Always log all candidate answers + scores (for observability + auditing).\n",
    "\n",
    "Cost control: Only run MultiChainComparison for high-risk / high-value queries (gating).\n",
    "\n",
    "Integration: Pair it with DSPy Optimizers — they can tune entire pipelines based on evaluation metrics.\n",
    "\n",
    "\n",
    "\n",
    "“MultiChainComparison is like having multiple students solve the same question and then the teacher picks the best solution. It improves accuracy by comparing different reasoning attempts automatically.”\n",
    "\n",
    "\n",
    "\n",
    "“In production AI, we don’t just want one answer — we want the best possible answer. MultiChainComparison lets us run multiple reasoning strategies (CoT, ReAct, PoT) and automatically score their outputs against metrics like semantic similarity or compliance rules. This gives us more reliable results, reduces hallucination, and makes pipelines auditable. Companies in finance, healthcare, and support use this approach to meet enterprise reliability standards.”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "587b5b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: To find the distance, we use the formula: Distance = Speed × Time.\n",
      "Given:\n",
      "Speed = 60 km/h\n",
      "Time = 2 hours\n",
      "\n",
      "Distance = 60 km/h * 2 hours\n",
      "Distance = 120 km\n",
      "Answer: 120\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# --- Signature ---\n",
    "class MathSig(dspy.Signature):\n",
    "    question = dspy.InputField(desc=\"Math problem to solve\")\n",
    "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning\")\n",
    "    answer = dspy.OutputField(desc=\"Final numeric answer\")\n",
    "\n",
    "# --- Create modules (same as before) ---\n",
    "cot = dspy.ChainOfThought(MathSig)\n",
    "pot = dspy.ProgramOfThought(MathSig)\n",
    "\n",
    "# --- Simple runner + exact-match comparator ---\n",
    "def run_and_compare(modules, signature, question):\n",
    "    results = []\n",
    "    for m in modules:\n",
    "        # call module just like you would: each returns an object with .reasoning and .answer\n",
    "        out = m(question=question)\n",
    "        # normalize answer for exact match (strip + lowercase)\n",
    "        ans_norm = getattr(out, \"answer\", \"\").strip().lower()\n",
    "        results.append({\"module\": m, \"out\": out, \"ans\": ans_norm})\n",
    "    # exact-match scoring: count matches for each answer\n",
    "    counts = {}\n",
    "    for r in results:\n",
    "        counts[r[\"ans\"]] = counts.get(r[\"ans\"], 0) + 1\n",
    "    # pick most common normalized answer (tie -> first module's answer)\n",
    "    best_ans_norm = max(counts.items(), key=lambda x: (x[1], x[0]))[0]\n",
    "    # find the result object that produced that normalized answer (prefer earlier module)\n",
    "    chosen = next(r for r in results if r[\"ans\"] == best_ans_norm)\n",
    "    return chosen[\"out\"]\n",
    "\n",
    "# --- Run ---\n",
    "out = run_and_compare([cot, pot], MathSig, question=\"If a train moves at 60 km/h for 2 hours, how far?\")\n",
    "print(\"Reasoning:\", getattr(out, \"reasoning\", None))\n",
    "print(\"Answer:\", getattr(out, \"answer\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b3d67",
   "metadata": {},
   "source": [
    "# DSPy Evaluation & Metrics\n",
    "🔹 1. Why evaluation matters\n",
    "\n",
    "LLMs are non-deterministic → same input can yield different outputs.\n",
    "\n",
    "Without structured evaluation, you can’t tell if your AI pipeline is actually improving.\n",
    "\n",
    "In production (banking, healthcare, legal, support), you must prove reliability with metrics.\n",
    "\n",
    "👉 DSPy builds evaluation directly into the framework: you can attach metrics, validators, and optimizers to pipelines.\n",
    "\n",
    "🔹 2. What kind of metrics are used?\n",
    "\n",
    "Exact Match (EM)\n",
    "\n",
    "Good for short answers, multiple-choice, or yes/no questions.\n",
    "\n",
    "Example: Q: “Capital of France?” A: “Paris” → EM = 1.\n",
    "\n",
    "Semantic F1 (token-level overlap)\n",
    "\n",
    "Better for free-text where wording differs.\n",
    "\n",
    "Example: “The train traveled 120 km” vs “It went 120 kilometers” → EM = 0, but F1 ~ 1.\n",
    "\n",
    "Rouge / BLEU / Similarity scores\n",
    "\n",
    "For summarization, translation, or long text.\n",
    "\n",
    "LLM-as-a-Judge (verifier model)\n",
    "\n",
    "Ask a small LM: “Which answer best matches the context?”\n",
    "\n",
    "Used when outputs are too open-ended for EM/F1.\n",
    "\n",
    "Custom checks / business rules\n",
    "\n",
    "Regex, numeric bounds, JSON schema validation, compliance rules.\n",
    "\n",
    "Example: In healthcare → answer must always include a disclaimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a40b918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 01:11:45 ERROR dspy.utils.parallelizer: Error for {'question': 'What is the capital of France?', 'context': 'France is a country in Europe. Its capital is Paris.', 'gold': 'Paris'}: 'dict' object has no attribute 'inputs'. Set `provide_traceback=True` for traceback.\n",
      "2025/09/17 01:11:45 ERROR dspy.utils.parallelizer: Error for {'question': '2+2?', 'context': 'Basic math', 'gold': '4'}: 'dict' object has no attribute 'inputs'. Set `provide_traceback=True` for traceback.\n",
      "2025/09/17 01:11:47 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 2 (0.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationResult(score=0.0, results=<list of 2 results>)\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Define signature + module\n",
    "class QnASignature(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    context = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "qa_model = dspy.ChainOfThought(QnASignature)\n",
    "\n",
    "# Define evaluation metric\n",
    "def semantic_f1(pred, gold):\n",
    "    pred_tokens = set(pred.lower().split())\n",
    "    gold_tokens = set(gold.lower().split())\n",
    "    overlap = len(pred_tokens & gold_tokens)\n",
    "    precision = overlap / len(pred_tokens) if pred_tokens else 0\n",
    "    recall = overlap / len(gold_tokens) if gold_tokens else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# Sample dataset\n",
    "dataset = [\n",
    "    {\"question\": \"What is the capital of France?\", \n",
    "     \"context\": \"France is a country in Europe. Its capital is Paris.\", \n",
    "     \"gold\": \"Paris\"},\n",
    "    {\"question\": \"2+2?\", \"context\": \"Basic math\", \"gold\": \"4\"}\n",
    "]\n",
    "\n",
    "# Initialize evaluator (requires devset)\n",
    "evaluator = Evaluate(\n",
    "    model=qa_model,\n",
    "    metric=semantic_f1,\n",
    "    devset=dataset,              # <-- fix: pass dataset here\n",
    "    input_keys=[\"question\", \"context\"],\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluator(program=qa_model)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a85ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
